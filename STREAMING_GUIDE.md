# æµå¼å“åº”ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

**å®æ–½æ—¥æœŸ**: 2026-01-31
**åŠŸèƒ½**: LLM æµå¼å“åº”æ”¯æŒ
**çŠ¶æ€**: âœ… å·²å®Œæˆ

## ğŸ¯ åŠŸèƒ½è¯´æ˜

Deep Agents Go ç°åœ¨æ”¯æŒæµå¼å“åº”ï¼Œå¯ä»¥å®æ—¶æ˜¾ç¤º LLM çš„ç”Ÿæˆå†…å®¹ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

### ä¸»è¦ä¼˜åŠ¿

1. **æ›´ä½çš„é¦–å­—èŠ‚å»¶è¿Ÿ** - æ— éœ€ç­‰å¾…å®Œæ•´å“åº”ï¼Œç«‹å³å¼€å§‹æ˜¾ç¤º
2. **æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ** - é€å­—æ˜¾ç¤ºï¼Œæ›´æœ‰äº¤äº’æ„Ÿ
3. **å¯æå‰ç»ˆæ­¢** - èŠ‚çœ token æˆæœ¬
4. **ç»Ÿä¸€çš„æ¥å£** - Anthropic å’Œ OpenAI ä½¿ç”¨ç›¸åŒçš„æµå¼ API

## ğŸ“¦ æ ¸å¿ƒç»„ä»¶

### 1. StreamEvent ç±»å‹

æµå¼äº‹ä»¶å®šä¹‰åœ¨ `pkg/llm/message.go`:

```go
type StreamEvent struct {
    Type       StreamEventType // äº‹ä»¶ç±»å‹
    Content    string          // æ–‡æœ¬å†…å®¹ï¼ˆå¢é‡ï¼‰
    ToolCall   *ToolCall       // å·¥å…·è°ƒç”¨
    StopReason string          // åœæ­¢åŸå› 
    Error      error           // é”™è¯¯ä¿¡æ¯
    Metadata   map[string]any  // å…ƒæ•°æ®
    Done       bool            // æ˜¯å¦å®Œæˆ
}
```

### 2. äº‹ä»¶ç±»å‹

```go
const (
    StreamEventTypeStart      // å¼€å§‹ç”Ÿæˆ
    StreamEventTypeText       // æ–‡æœ¬å†…å®¹
    StreamEventTypeToolUse    // å·¥å…·è°ƒç”¨
    StreamEventTypeEnd        // ç”Ÿæˆç»“æŸ
    StreamEventTypeError      // é”™è¯¯
    StreamEventTypePing       // å¿ƒè·³
    StreamEventTypeMetadata   // å…ƒæ•°æ®
)
```

### 3. Client æ¥å£

æ‰©å±•çš„ `llm.Client` æ¥å£ï¼š

```go
type Client interface {
    // Generate ç”Ÿæˆå“åº”ï¼ˆéæµå¼ï¼‰
    Generate(ctx context.Context, req *ModelRequest) (*ModelResponse, error)

    // StreamGenerate ç”Ÿæˆå“åº”ï¼ˆæµå¼ï¼‰
    StreamGenerate(ctx context.Context, req *ModelRequest) (<-chan StreamEvent, error)

    // CountTokens ä¼°ç®— token æ•°é‡
    CountTokens(messages []Message) int
}
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ç”¨æ³•

```go
package main

import (
    "context"
    "fmt"
    "github.com/zhoucx/deepagents-go/pkg/llm"
)

func main() {
    // åˆ›å»ºå®¢æˆ·ç«¯
    client := llm.NewAnthropicClient(apiKey, "claude-3-5-sonnet-20241022", "")

    // æ„å»ºè¯·æ±‚
    req := &llm.ModelRequest{
        Messages: []llm.Message{
            {Role: llm.RoleUser, Content: "ä»‹ç»ä¸€ä¸‹ Go è¯­è¨€"},
        },
        MaxTokens:   500,
        Temperature: 0.7,
    }

    // è°ƒç”¨æµå¼ API
    stream, err := client.StreamGenerate(ctx, req)
    if err != nil {
        log.Fatal(err)
    }

    // å¤„ç†æµå¼äº‹ä»¶
    for event := range stream {
        switch event.Type {
        case llm.StreamEventTypeText:
            fmt.Print(event.Content) // å®æ—¶æ˜¾ç¤ºæ–‡æœ¬
        case llm.StreamEventTypeEnd:
            fmt.Println("\n[å®Œæˆ]")
        case llm.StreamEventTypeError:
            fmt.Printf("[é”™è¯¯: %v]\n", event.Error)
        }
    }
}
```

### å®Œæ•´ç¤ºä¾‹

å‚è§ `cmd/examples/streaming/main.go`:

- Anthropic æµå¼å“åº”
- OpenAI æµå¼å“åº”
- å¯¹æ¯”éæµå¼å’Œæµå¼å“åº”

### è¿è¡Œç¤ºä¾‹

```bash
# è®¾ç½® API Key
export ANTHROPIC_API_KEY=your_key

# å¯é€‰ï¼šè®¾ç½® OpenAI Key
export OPENAI_API_KEY=your_openai_key

# è¿è¡Œç¤ºä¾‹
go run ./cmd/examples/streaming/main.go
```

## ğŸ¨ äº‹ä»¶å¤„ç†æ¨¡å¼

### æ¨¡å¼ 1ï¼šç®€å•æ˜¾ç¤º

```go
for event := range stream {
    if event.Type == llm.StreamEventTypeText {
        fmt.Print(event.Content)
    }
}
```

### æ¨¡å¼ 2ï¼šç´¯ç§¯å†…å®¹

```go
var fullContent string

for event := range stream {
    switch event.Type {
    case llm.StreamEventTypeText:
        fullContent += event.Content
        fmt.Print(event.Content)
    case llm.StreamEventTypeEnd:
        // fullContent ç°åœ¨åŒ…å«å®Œæ•´å†…å®¹
        saveToDatabase(fullContent)
    }
}
```

### æ¨¡å¼ 3ï¼šå¤„ç†å·¥å…·è°ƒç”¨

```go
for event := range stream {
    switch event.Type {
    case llm.StreamEventTypeText:
        fmt.Print(event.Content)
    case llm.StreamEventTypeToolUse:
        fmt.Printf("\n[è°ƒç”¨å·¥å…·: %s]\n", event.ToolCall.Name)
        // æ‰§è¡Œå·¥å…·...
    case llm.StreamEventTypeEnd:
        fmt.Println("\n[å®Œæˆ]")
    }
}
```

### æ¨¡å¼ 4ï¼šæå‰ç»ˆæ­¢

```go
ctx, cancel := context.WithCancel(context.Background())
defer cancel()

stream, _ := client.StreamGenerate(ctx, req)

for event := range stream {
    if event.Type == llm.StreamEventTypeText {
        fmt.Print(event.Content)

        // å¦‚æœç”Ÿæˆäº†è¶³å¤Ÿçš„å†…å®¹ï¼Œæå‰ç»ˆæ­¢
        if len(fullContent) > 1000 {
            cancel() // å–æ¶ˆè¯·æ±‚
            break
        }
    }
}
```

## ğŸ”§ å®ç°ç»†èŠ‚

### Anthropic å®¢æˆ·ç«¯

- ä½¿ç”¨ `Messages.NewStreaming()` API
- å¤„ç† `ContentBlockDelta` äº‹ä»¶
- è§£æå·¥å…·è°ƒç”¨ JSON
- æ”¯æŒå¿ƒè·³äº‹ä»¶

### OpenAI å®¢æˆ·ç«¯

- ä½¿ç”¨ `CreateChatCompletionStream()` API
- å¤„ç† `Delta` å¢é‡
- ç´¯ç§¯å·¥å…·è°ƒç”¨å‚æ•°
- æ”¯æŒå¤šä¸ªå¹¶å‘å·¥å…·è°ƒç”¨

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **èµ„æºæ¸…ç†**: channel ä¼šè‡ªåŠ¨å…³é—­ï¼Œä½†å»ºè®®ä½¿ç”¨ `defer cancel()` ç¡®ä¿èµ„æºé‡Šæ”¾

2. **é”™è¯¯å¤„ç†**: æµå¼è¿‡ç¨‹ä¸­çš„é”™è¯¯ä¼šé€šè¿‡ `StreamEventTypeError` äº‹ä»¶å‘é€

3. **è¶…æ—¶æ§åˆ¶**: å»ºè®®ä½¿ç”¨ `context.WithTimeout()` è®¾ç½®è¶…æ—¶

4. **å¹¶å‘å®‰å…¨**: æ¯ä¸ªæµå¼è¯·æ±‚åº”åœ¨ç‹¬ç«‹çš„ goroutine ä¸­å¤„ç†

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### éæµå¼å“åº”
- âœ“ ç®€å•æ˜“ç”¨
- âœ“ ä¸€æ¬¡æ€§è¿”å›
- âœ— ç­‰å¾…æ—¶é—´é•¿
- âœ— æ— æ³•æå‰ç»ˆæ­¢

### æµå¼å“åº”
- âœ“ é¦–å­—èŠ‚å»¶è¿Ÿä½
- âœ“ ç”¨æˆ·ä½“éªŒå¥½
- âœ“ å¯æå‰ç»ˆæ­¢
- âœ— ä»£ç ç¨å¤æ‚

## ğŸ”® æœªæ¥è®¡åˆ’

- [x] Agent å±‚é¢çš„æµå¼æ‰§è¡Œ âœ… å·²å®Œæˆ
- [ ] CLI å·¥å…·é›†æˆæµå¼æ˜¾ç¤º
- [ ] æµå¼å“åº”çš„æ€§èƒ½ä¼˜åŒ–
- [ ] æ›´å¤šæµå¼äº‹ä»¶ç±»å‹

## ğŸ¯ Agent æµå¼æ‰§è¡Œ

### ä½¿ç”¨æ–¹æ³•

```go
executor := agent.NewExecutor(config)

stream, err := executor.InvokeStream(ctx, input)
if err != nil {
    log.Fatal(err)
}

for event := range stream {
    switch event.Type {
    case agent.AgentEventTypeLLMText:
        fmt.Print(event.Content) // å®æ—¶æ˜¾ç¤º
    case agent.AgentEventTypeToolStart:
        fmt.Printf("[è°ƒç”¨å·¥å…·: %s]\n", event.ToolCall.Name)
    case agent.AgentEventTypeToolResult:
        fmt.Printf("[ç»“æœ: %s]\n", event.ToolResult.Content)
    case agent.AgentEventTypeEnd:
        fmt.Println("[å®Œæˆ]")
    }
}
```

### Agent äº‹ä»¶ç±»å‹

| äº‹ä»¶ç±»å‹ | è¯´æ˜ | æ•°æ® |
|---------|------|------|
| `Start` | Agent å¼€å§‹ | - |
| `LLMStart` | LLM å¼€å§‹ç”Ÿæˆ | Iteration |
| `LLMText` | LLM æ–‡æœ¬å†…å®¹ | Content, Iteration |
| `LLMToolCall` | LLM å·¥å…·è°ƒç”¨ | ToolCall, Iteration |
| `LLMEnd` | LLM ç”Ÿæˆç»“æŸ | Iteration |
| `ToolStart` | å·¥å…·å¼€å§‹æ‰§è¡Œ | ToolCall, Iteration |
| `ToolResult` | å·¥å…·æ‰§è¡Œç»“æœ | ToolResult, Iteration |
| `IterationEnd` | è¿­ä»£ç»“æŸ | Iteration |
| `End` | Agent å®Œæˆ | Metadata |
| `Error` | é”™è¯¯ | Error |

### ç¤ºä¾‹ç¨‹åº

å‚è§ `cmd/examples/agent_streaming/main.go`


## ğŸ“š ç›¸å…³æ–‡æ¡£

- [LLM Client æ¥å£](../pkg/llm/client.go)
- [æµå¼äº‹ä»¶å®šä¹‰](../pkg/llm/message.go)
- [Anthropic å®ç°](../pkg/llm/anthropic.go)
- [OpenAI å®ç°](../pkg/llm/openai.go)
- [ç¤ºä¾‹ç¨‹åº](../cmd/examples/streaming/main.go)

---

**æœ€åæ›´æ–°**: 2026-01-31
